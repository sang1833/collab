{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Prompt Design - Best Practices\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fprompts%2Fintro_prompt_design.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://raw.githubusercontent.com/primer/octicons/refs/heads/main/icons/mark-github-24.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://goo.gle/4fWHlze\">\n",
        "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Polong Lin](https://github.com/polong-lin) |\n",
        "| [Karl Weinmeister](https://github.com/kweinmeister) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook covers the essentials of prompt engineering, including some best practices.\n",
        "\n",
        "Learn more about prompt design in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview).\n",
        "\n",
        "In this notebook, you learn best practices around prompt engineering -- how to design prompts to improve the quality of your responses.\n",
        "\n",
        "This notebook covers the following best practices for prompt engineering:\n",
        "\n",
        "- Be concise\n",
        "- Be specific and well-defined\n",
        "- Ask one task at a time\n",
        "- Turn generative tasks into classification tasks\n",
        "- Improve response quality by including examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "outputId": "c79bf1fa-41f6-4150-bbd6-3abd1fabbe3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m724.4/724.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06489bd14f16"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import GenerateContentConfig\n",
        "\n",
        "# fmt: off\n",
        "PROJECT_ID = \"roleplay-ai-narrator-22\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "# fmt: on\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QqRWdPGmW3NJ"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnFPpCRtXRl4"
      },
      "source": [
        "### Load model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IQYu_9SvXQah"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVOtUNJ5X0PY"
      },
      "source": [
        "## Prompt engineering best practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv_e0fEPX60q"
      },
      "source": [
        "Prompt engineering is all about how to design your prompts so that the response is what you were indeed hoping to see.\n",
        "\n",
        "The idea of using \"unfancy\" prompts is to minimize the noise in your prompt to reduce the possibility of the LLM misinterpreting the intent of the prompt. Below are a few guidelines on how to engineer \"unfancy\" prompts.\n",
        "\n",
        "In this section, you'll cover the following best practices when engineering prompts:\n",
        "\n",
        "* Be concise\n",
        "* Be specific, and well-defined\n",
        "* Ask one task at a time\n",
        "* Improve response quality by including examples\n",
        "* Turn generative tasks to classification tasks to improve safety"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pY4XX0OX9_Y"
      },
      "source": [
        "### Be concise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlRpxyxGYA1K"
      },
      "source": [
        "üõë Not recommended. The prompt below is unnecessarily verbose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YKV4G-CfXdbi",
        "outputId": "903a5b8e-f4d6-42da-94e3-983d14021ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "That's a fantastic niche! Here are some name ideas for a dried flower shop, categorized by the vibe they evoke:\n\n**I. Elegant & Timeless:**\n*   Everlasting Blooms\n*   The Preserved Petal\n*   Timeless Stems\n*   Heirloom Hues\n*   The Botanical Archive\n*   Flora Perpetua (Latin for \"eternal flowers\")\n*   The Enduring Arrangement\n*   Still Bloom Studio\n\n**II. Descriptive & Clear:**\n*   The Dried Bloom Co.\n*   Petal & Press\n*   Air & Bloom\n*   Botanical Dry Goods\n*   The Dry Garden Shop\n*   Gathered & Dried\n*   Muted Petals\n*   Harvested Hues\n\n**III. Evocative & Rustic/Bohemian:**\n*   The Rustic Stem\n*   Boho Botanical\n*   Sun-Kissed Petals (implies the drying process)\n*   Whispering Wreaths\n*   Earthbound Blooms\n*   The Olde Bloomery (uses \"olde\" for charm)\n*   Faded & Found Florals\n*   Driftwood & Blooms\n\n**IV. Playful & Unique:**\n*   The Second Bloom (implies a new life for flowers)\n*   Petal & Prose (suggests storytelling or lasting beauty)\n*   Muted Marvels\n*   Bloom & Bone (if you like a slightly edgier, natural aesthetic)\n*   The Unfading Floral\n*   Dusty Rose Design (if roses are a focus, \"dusty\" implies dried color)\n*   Wither & Whimsy (playful take on the drying process)\n\n**Tips for Choosing:**\n*   **Say it out loud:** Does it roll off the tongue?\n*   **Check availability:** Is the domain name and social media handle available?\n*   **Consider your target audience:** Who are you trying to attract?\n*   **Reflect your aesthetic:** Does the name match the look and feel of your bouquets?\n*   **Short & Memorable:** Easier for customers to recall.\n\nGood luck with your beautiful shop!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"What do you think could be a good name for a flower shop that specializes in selling bouquets of dried flowers more than fresh flowers?\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJexRHJYnmC"
      },
      "source": [
        "‚úÖ Recommended. The prompt below is to the point and concise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VHetn9lCYrXB",
        "outputId": "a6b764df-ca72-4353-f8a8-35d336a09241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are some name suggestions for a flower shop specializing in dried flower bouquets, categorized by their feel:\n\n**Elegant & Timeless:**\n\n1.  **Everlasting Blooms**\n2.  **Timeless Petals**\n3.  **The Enduring Bloom**\n4.  **Preserved Petal Co.**\n5.  **Heirloom Blooms**\n6.  **Botanical Keepsakes**\n7.  **The Floral Archive**\n8.  **Eternal Flora**\n9.  **The Dried Gardenia**\n10. **Sanctuary of Stems**\n\n**Whimsical & Bohemian:**\n\n11. **Wild & Dried**\n12. **Moonlit Blooms**\n13. **Faded Petal Studio**\n14. **The Whispering Willow Blooms**\n15. **Earthy Petals**\n16. **Boho Blooms & Bundles**\n17. **Rustic Petal Co.**\n18. **Gypsy Blooms**\n19. **The Sun-Kissed Stem**\n20. **Dreamdust Dried Flowers**\n\n**Modern & Minimalist:**\n\n21. **Bloom & Dry**\n22. **Flora Dry**\n23. **The Dried Co.**\n24. **Petal Preserve**\n25. **Stem & Stone (or Stem & Dry)**\n26. **Everdry Botanical**\n27. **Pure Preserve**\n28. **The Dried Edit**\n29. **Muted Bloom**\n30. **Dried.** (with a tagline, e.g., \"Dried. Lasting Beauty.\")\n\n**Descriptive & Direct:**\n\n31. **The Dried Bouquet Shop**\n32. **Everlasting Arrangements**\n33. **Preserved Petals & More**\n34. **The Dried Flower Emporium**\n35. **Naturally Dried Blooms**\n36. **The Petal Preservation Co.**\n37. **Bouquets That Last**\n38. **Dried & Dusted Blooms**\n39. **The Curated Dry Flower**\n40. **Forever Flowers Boutique**\n\n**Tips for Choosing:**\n\n*   **Check Availability:** See if the name and a corresponding domain name (e.g., .com) are available.\n*   **Target Audience:** Who are you trying to attract? A whimsical name for a younger, artistic crowd, or an elegant name for a more sophisticated clientele?\n*   **Memorability & Pronunciation:** Is it easy to remember and say?\n*   **Brand Personality:** Does the name reflect the overall feeling and style you want your shop to have?\n*   **Future Growth:** Will the name still make sense if you decide to expand your offerings beyond just bouquets (e.g., dried flower art, workshops)?\n\nGood luck!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Suggest a name for a flower shop that sells bouquets of dried flowers\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXTAvdOHY0OC"
      },
      "source": [
        "### Be specific, and well-defined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTH4GEIgY1dp"
      },
      "source": [
        "Suppose that you want to brainstorm creative ways to describe Earth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5BmXBiGY4KC"
      },
      "source": [
        "üõë The prompt below might be a bit too generic (which is certainly OK if you'd like to ask a generic question!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eHBaMvv7Y6mR",
        "outputId": "e90440c3-ad63-4912-a707-85d3fe7dde5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Earth, our home planet, is a truly remarkable and unique celestial body within our solar system. Here's a comprehensive overview:\n\n---\n\n### **1. General Characteristics**\n\n*   **Third Planet:** Earth is the third planet from the Sun.\n*   **Fifth Largest:** It is the fifth largest planet in our solar system by diameter and mass.\n*   **\"Blue Planet\":** From space, Earth appears predominantly blue due to the abundance of liquid water on its surface.\n*   **Only Known Abode of Life:** Earth is the only astronomical object known to harbor life. This is often attributed to its position in the \"habitable zone\" (or \"Goldilocks zone\") around the Sun, where conditions are just right for liquid water to exist.\n\n---\n\n### **2. Physical Features**\n\n*   **Shape:** While often depicted as a perfect sphere, Earth is actually an **oblate spheroid**, meaning it bulges slightly at the equator and is flattened at the poles due to its rotation.\n*   **Size:**\n    *   Equatorial Diameter: ~12,756 km (7,926 miles)\n    *   Polar Diameter: ~12,714 km (7,900 miles)\n*   **Surface:**\n    *   **Water (71%):** Covered mostly by oceans, seas, lakes, and rivers. This vast amount of liquid water is crucial for life.\n    *   **Land (29%):** Consists of seven continents and numerous islands. The Earth's crust is divided into several large **tectonic plates** that are constantly moving, causing phenomena like earthquakes, volcanic eruptions, and mountain building.\n*   **Atmosphere:** A thin layer of gases surrounding the planet, vital for life and regulating temperature.\n    *   **Composition:** Approximately 78% Nitrogen, 21% Oxygen, 0.9% Argon, 0.04% Carbon Dioxide, and trace amounts of other gases and water vapor.\n    *   **Layers:** Divided into troposphere, stratosphere, mesosphere, thermosphere, and exosphere, each with distinct characteristics.\n    *   **Functions:** Protects life from harmful solar radiation (ozone layer in the stratosphere), moderates temperatures, and provides breathable air.\n*   **Magnetic Field:** Generated by the molten iron in Earth's outer core, this field acts as a protective shield (the magnetosphere) that deflects harmful charged particles from the Sun (solar wind), preventing the stripping away of the atmosphere and protecting organisms from radiation.\n\n---\n\n### **3. Internal Structure**\n\nEarth's interior is composed of distinct layers:\n\n*   **Crust:** The outermost solid layer, relatively thin (5-70 km). It's where we live and where tectonic plates are found.\n*   **Mantle:** A thick, semi-solid layer (about 2,900 km deep) beneath the crust, made of hot, dense rock that slowly flows due to convection currents. These currents drive plate tectonics.\n*   **Outer Core:** A liquid layer (about 2,200 km thick) composed mainly of molten iron and nickel. Its movement generates Earth's magnetic field.\n*   **Inner Core:** The innermost solid sphere (about 1,220 km radius), primarily made of iron and nickel. It's incredibly hot (temperatures comparable to the surface of the Sun) but remains solid due to immense pressure.\n\n---\n\n### **4. Movement & Time**\n\n*   **Rotation:** Earth rotates on its axis once every ~23 hours, 56 minutes, and 4 seconds, causing the cycle of day and night. The axis is tilted about 23.5 degrees relative to its orbit.\n*   **Revolution:** Earth orbits the Sun once every ~365.25 days, defining a year.\n*   **Seasons:** The 23.5-degree axial tilt, combined with Earth's revolution around the Sun, is responsible for the seasons. As Earth orbits, different parts of the planet are tilted towards or away from the Sun, receiving more direct sunlight at different times of the year.\n\n---\n\n### **5. Life and Ecosystems**\n\n*   **Biodiversity:** Earth hosts an astonishing array of life forms, from microscopic bacteria to giant whales, inhabiting diverse ecosystems (biomes) like forests, deserts, oceans, grasslands, and tundras.\n*   **Interconnected Systems:** All of Earth's systems ‚Äì atmosphere, hydrosphere (water), lithosphere (land), and biosphere (life) ‚Äì are intricately linked and constantly interact, forming a complex and dynamic planet.\n\n---\n\n### **6. Humanity's Role**\n\n*   **Source of Resources:** Earth provides all the resources necessary for human civilization, including food, water, minerals, and energy.\n*   **Impact:** Human activities have a significant and growing impact on Earth's systems, leading to challenges such as climate change, deforestation, pollution, species extinction, and resource depletion.\n*   **Stewardship:** Recognizing these impacts, there's a growing global effort towards sustainability, conservation, and understanding our planet better to protect it for future generations.\n\n---\n\nIn essence, Earth is a dynamic, living world, perfectly balanced to sustain an incredible diversity of life, making it a unique and invaluable treasure in the cosmos."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Tell me about Earth\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iyvEbteZnFL"
      },
      "source": [
        "‚úÖ Recommended. The prompt below is specific and well-defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JQ80z8urZnne",
        "outputId": "2d371b3c-6eda-491f-c582-110808290e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Earth holds a special place in the cosmos due to a remarkable combination of factors that have allowed life, as we know it, to not just exist, but to flourish and evolve into complex forms. Here's a list of ways Earth is unique compared to most other known planets:\n\n1.  **Abundant and Stable Liquid Surface Water:** While water exists in other forms (ice, vapor) on other celestial bodies, Earth is the only known planet with vast, stable oceans of liquid water on its surface. This is fundamental for life.\n\n2.  **A Biologically-Driven Oxygen-Rich Atmosphere:** Earth's atmosphere is about 21% oxygen, a gas produced almost entirely by photosynthetic life (plants, algae, cyanobacteria). This oxygen is crucial for the respiration of complex life forms and the formation of the ozone layer. No other known planet has a significant free oxygen atmosphere.\n\n3.  **Active Plate Tectonics:** Earth's crust is divided into several large plates that are constantly moving. This process recycles elements, creates mountains, volcanoes, and ocean trenches, regulates the planet's temperature by affecting carbon dioxide levels in the atmosphere, and is thought to be essential for long-term climate stability and the evolution of life. While signs of past tectonic activity exist elsewhere, Earth's active, global plate tectonics system is unique.\n\n4.  **A Large, Stabilizing Moon:** Earth's Moon is unusually large relative to its planet. Its gravitational pull stabilizes Earth's axial tilt, preventing extreme wobbles that could lead to drastic and rapid climate changes. The Moon also drives tides, which played a role in the early evolution of life.\n\n5.  **A Strong, Global Magnetosphere:** Earth's molten iron core generates a powerful magnetic field that extends far into space. This magnetosphere deflects harmful charged particles from the solar wind and cosmic rays, protecting our atmosphere from erosion and shielding surface life from dangerous radiation.\n\n6.  **Optimal \"Goldilocks Zone\" Location:** Earth orbits the Sun at just the right distance ‚Äì not too hot, not too cold ‚Äì allowing for the persistent presence of liquid water. This, combined with its atmospheric composition, creates a moderate temperature range.\n\n7.  **Unparalleled Biodiversity:** Earth hosts an astonishing array of life forms, from microscopic bacteria to enormous whales, inhabiting every conceivable niche. The sheer variety and complexity of ecosystems and species is unmatched by any other known planet.\n\n8.  **Intelligent and Technologically Advanced Life:** As far as we know, Earth is the only planet in the universe to host intelligent life capable of scientific inquiry, complex communication, technological innovation, and self-awareness to the extent of building civilizations.\n\n9.  **A Dynamic and Self-Regulating System (Gaia Hypothesis):** Earth's various systems (atmosphere, oceans, geology, and life) interact in complex ways to maintain conditions favorable for life. For example, the carbon cycle, driven in part by life and plate tectonics, helps regulate the planet's climate over geological timescales.\n\n10. **Evidence of Long-Term Climatic Stability:** While Earth's climate has varied, it has maintained conditions suitable for life for billions of years, avoiding runaway greenhouse effects (like Venus) or permanent deep freezes (like Mars). This long-term stability has been crucial for complex life to evolve.\n\nThese factors, individually rare and collectively unique, make Earth a truly special place in the vastness of the cosmos."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Generate a list of ways that makes Earth unique compared to other planets\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5kmfZYHZsJ7"
      },
      "source": [
        "### Ask one task at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsAezxeYZuUN"
      },
      "source": [
        "üõë Not recommended. The prompt below has two parts to the question that could be asked separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ElywPXpuZtWf",
        "outputId": "23ddf813-6af0-4d00-a9e4-577d08f2c3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "You've asked two classic and fascinating questions! Let's break them down.\n\n---\n\n### What's the best method of boiling water?\n\nThe \"best\" method depends on your priorities (speed, energy efficiency, availability, safety), but for **most everyday situations, an electric kettle is generally considered the best.**\n\nHere's a breakdown of common methods and their pros/cons:\n\n1.  **Electric Kettle (Best for most people):**\n    *   **Pros:**\n        *   **Speed:** Very fast, often boiling water in just a couple of minutes for typical household quantities.\n        *   **Efficiency:** Highly energy-efficient. The heating element is immersed directly in the water, and kettles are often insulated to minimize heat loss.\n        *   **Safety:** Most have automatic shut-off features when the water boils, preventing them from boiling dry.\n        *   **Convenience:** Simple to use, just fill and switch on.\n    *   **Cons:** Requires electricity, not portable for camping/off-grid.\n\n2.  **Stovetop Kettle or Pot:**\n    *   **Pros:**\n        *   **Availability:** Most kitchens have a stove and a pot.\n        *   **Versatility:** Can boil large quantities.\n        *   **No specific appliance needed.**\n    *   **Cons:**\n        *   **Slower:** Generally takes longer than an electric kettle.\n        *   **Less Efficient:** A significant amount of heat escapes into the air around the pot, especially with gas stoves.\n        *   **Less Safe:** No auto-shutoff; can boil dry if forgotten, potentially causing damage or fire.\n\n3.  **Microwave:**\n    *   **Pros:**\n        *   **Speed (small quantities):** Can be quick for a single cup of water.\n        *   **Convenience:** Uses an appliance you likely already have.\n    *   **Cons:**\n        *   **Safety Hazard (Superheating):** Water can become superheated (heated above its boiling point without actually boiling). When disturbed (e.g., adding a spoon, or even just moving the cup), it can erupt violently, causing severe burns. This is a significant risk.\n        *   **Uneven Heating:** Doesn't always heat water uniformly.\n        *   **Less Efficient:** For boiling, it's generally less energy-efficient than an electric kettle, especially for larger volumes.\n        *   **No Auto-Shutoff.**\n\n4.  **Immersion Heater:**\n    *   **Pros:**\n        *   **Very Fast:** Heats water directly and quickly.\n        *   **Portable:** Good for travel.\n    *   **Cons:**\n        *   **Significant Safety Risk:** Exposed electrical element, risk of electrocution if not used correctly, can boil dry, fire hazard if left unattended. Not recommended for casual home use.\n\n**Key Tips for Boiling Water (regardless of method):**\n\n*   **Cover the pot/kettle:** This traps steam and heat, significantly speeding up the boiling process and saving energy.\n*   **Only boil what you need:** Boiling excess water wastes energy and time.\n*   **Start with hot tap water (if safe):** If your tap water is potable and heats up quickly, starting with warmer water can reduce boiling time. (Note: Some people prefer not to consume hot tap water directly due to potential for dissolved minerals or contaminants from pipes.)\n*   **Clean your kettle/pot:** Limescale buildup in electric kettles can reduce efficiency.\n\n---\n\n### Why is the sky blue?\n\nThe blue color of the sky is primarily due to a phenomenon called **Rayleigh scattering**, named after the 19th-century British physicist Lord Rayleigh.\n\nHere's how it works:\n\n1.  **Sunlight is White Light:** Sunlight appears white to us, but it's actually composed of all the colors of the rainbow (a spectrum of wavelengths), from red (longest wavelength) to violet (shortest wavelength).\n2.  **Earth's Atmosphere:** Our atmosphere is made up of tiny gas molecules, primarily nitrogen (about 78%) and oxygen (about 21%), along with other trace gases and particles.\n3.  **Scattering of Light:** When sunlight enters the atmosphere, it collides with these gas molecules. These collisions cause the light to be redirected or \"scattered\" in different directions.\n4.  **Rayleigh Scattering Explained:** Rayleigh scattering states that **shorter wavelengths of light are scattered much more efficiently than longer wavelengths.**\n    *   **Blue and Violet light** have very short wavelengths.\n    *   **Red, Orange, and Yellow light** have longer wavelengths.\n5.  **The Blue Sky:** Because blue and violet light have the shortest wavelengths, they are scattered most intensely by the tiny nitrogen and oxygen molecules in the atmosphere. This scattered blue light goes in all directions, including towards our eyes, making the sky appear blue.\n6.  **Why not violet?** While violet light is scattered even more than blue, there are two main reasons we see blue rather than violet:\n    *   The sun emits slightly less violet light than blue light.\n    *   Our eyes are more sensitive to blue light than to violet light.\n7.  **Why Sunsets are Red/Orange:** When the sun is low on the horizon (at sunrise or sunset), its light has to travel through a much greater amount of atmosphere to reach our eyes. During this longer journey, most of the blue and violet light is scattered away *before* it reaches us. This leaves primarily the longer-wavelength colors ‚Äì red, orange, and yellow ‚Äì to pass through more directly, giving us those beautiful warm hues.\n\nIn summary, the tiny gas molecules in our atmosphere act like miniature prisms, preferentially scattering the shorter, bluer wavelengths of sunlight, painting our sky blue!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"What's the best method of boiling water and why is the sky blue?\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejzahazBZ8vk"
      },
      "source": [
        "‚úÖ Recommended. The prompts below asks one task a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C5ckp2F0Z_Ba",
        "outputId": "a25994e2-484c-40bc-b08e-5486c7fbcfe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The \"best\" method for boiling water really depends on your priorities: **speed, efficiency, convenience, volume, and safety.**\n\nHere's a breakdown of common methods and their pros/cons:\n\n---\n\n### 1. Electric Kettle (The Overall Winner for Most People)\n\n**Why it's often considered the best:**\n\n*   **Speed:** Generally the fastest method for small to medium volumes (up to 1.7 liters). The heating element is directly submerged in the water, transferring heat very efficiently.\n*   **Efficiency:** Highly energy-efficient. Less heat is lost to the surroundings compared to a stovetop.\n*   **Convenience:** Easy to use (fill, plug in, press a button). Many have auto-shutoff when the water boils. Cordless designs are common.\n*   **Safety:** Auto-shutoff features prevent dry boiling and reduce the risk of accidents.\n*   **Portability:** Can be used in any room with an outlet.\n\n**Best for:** Daily use for tea, coffee, instant noodles, quick cooking prep.\n\n---\n\n### 2. Stovetop Pot (Reliable and Versatile)\n\n**Why it's a strong contender:**\n\n*   **Versatility:** Can boil any volume, from a single cup in a small saucepan to several gallons in a large stockpot.\n*   **Availability:** Most homes have a stovetop.\n*   **No Extra Appliance:** Doesn't require purchasing or storing another dedicated appliance.\n*   **Control (Gas):** Gas stovetops offer precise control over heat.\n\n**Tips for Stovetop Boiling:**\n\n*   **Use a Lid:** A lid traps steam and heat, significantly reducing boiling time and energy consumption.\n*   **Match Pot Size to Burner:** Use a pot that fits the burner to minimize heat loss around the sides.\n*   **Choose the Right Pot:** Stainless steel or copper-bottomed pots conduct heat well.\n\n**Best for:** Boiling large quantities of water, when an electric kettle isn't available, or for specific cooking tasks that require stovetop presence.\n\n---\n\n### 3. Microwave (Use with Caution, Not Recommended for Boiling)\n\n**Why it's generally NOT the best, and potentially dangerous:**\n\n*   **Superheating Risk:** This is the most significant danger. Water in a microwave can heat past its boiling point without visibly bubbling. When disturbed (e.g., adding a tea bag, or even just moving the cup), it can violently erupt, causing severe burns.\n*   **Uneven Heating:** Microwaves can heat water unevenly, leading to hot spots and cold spots.\n*   **Slow for Volume:** Only practical for very small amounts (a single mug). For larger quantities, it's slow and inefficient.\n*   **No Auto-Shutoff:** Requires constant monitoring to prevent over-boiling.\n\n**Best for:** *Almost never for boiling.* If you absolutely must, use a non-sealed, microwave-safe container (like a ceramic mug), add a non-metallic object (like a wooden stir stick) to provide a nucleation site for bubbles, and only heat for short intervals. Even then, proceed with extreme caution.\n\n---\n\n### 4. Immersion Heater (Travel & Niche Use)\n\n**Why it's a specialized option:**\n\n*   **Portability:** Very small and lightweight, ideal for travel.\n*   **Speed (for small volumes):** Can heat a single cup quickly, similar to an electric kettle.\n*   **Efficiency:** Direct contact with water makes it efficient.\n\n**Cons:**\n\n*   **Safety Concerns:** Must be fully immersed. Can burn surfaces if not handled carefully. Many lack auto-shutoff, requiring constant supervision.\n*   **Volume:** Only suitable for very small quantities.\n*   **Durability:** Often less robust than other options.\n\n**Best for:** Travelers, camping (if electricity is available), or anyone needing to boil a single cup of water in a non-traditional setting.\n\n---\n\n## General Tips for Boiling Water (Regardless of Method):\n\n1.  **Only Boil What You Need:** This is the most significant energy-saving tip. Boiling an extra liter you don't use wastes a lot of energy.\n2.  **Use Fresh Water:** For the best taste, use fresh, cold water from the tap. Re-boiling previously boiled water can slightly alter its taste due to dissolved gasses escaping.\n3.  **Keep Equipment Clean:** Limescale buildup in kettles can reduce efficiency and affect taste. Descale regularly.\n4.  **Safety First:** Hot water causes severe burns. Always exercise caution, especially around children.\n\n---\n\n**In conclusion:**\n\nFor the average home user, the **electric kettle** offers the best balance of speed, efficiency, convenience, and safety. If you need to boil large volumes or prefer a traditional method, a **stovetop pot with a lid** is an excellent choice. Avoid the microwave for boiling water if possible due to safety concerns."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"What's the best method of boiling water?\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KwUzhud4aA89",
        "outputId": "92f993e4-9e05-4b6d-af34-1b7a77c29504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\n\n1.  **Sunlight is White Light:** The light from the sun, which appears white to us, is actually made up of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet). Each color has a different wavelength, with violet and blue having shorter wavelengths and red and orange having longer wavelengths.\n\n2.  **Earth's Atmosphere:** As sunlight travels towards Earth, it enters our atmosphere, which is composed of tiny gas molecules (mostly nitrogen and oxygen) and some small dust particles.\n\n3.  **Scattering of Light:** When sunlight encounters these tiny particles in the atmosphere, some of the light is scattered in different directions. The amount of scattering depends on the wavelength of the light and the size of the particles.\n\n4.  **Rayleigh Scattering Explained:**\n    *   For particles much smaller than the wavelength of light (like nitrogen and oxygen molecules), **shorter wavelengths of light (blue and violet) are scattered much more strongly and efficiently than longer wavelengths (red, orange, yellow).**\n    *   Blue light is scattered about 10 times more than red light.\n\n5.  **Why We See Blue:**\n    *   Because blue and violet light are scattered in all directions more effectively than other colors, when we look up at the sky, we see this scattered blue light coming from all directions. This makes the sky appear blue.\n    *   While violet light is scattered even more strongly than blue, our eyes are more sensitive to blue light, and there's also slightly less violet light in the sun's spectrum to begin with, so the sky primarily appears blue to us.\n\n6.  **Why Sunsets are Red/Orange:**\n    *   At sunrise or sunset, the sun's light has to travel through a much greater amount of atmosphere to reach our eyes.\n    *   During this longer journey, even *more* of the blue and violet light is scattered away, often far off to the sides.\n    *   This leaves mostly the longer-wavelength red, orange, and yellow light to reach us directly, making the sun and the surrounding sky appear warm-colored.\n\nSo, in essence, the sky is blue because the molecules in Earth's atmosphere scatter blue light more efficiently than other colors, spreading it across the visible sky."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Why is the sky blue?\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJIL2RTQaGcT"
      },
      "source": [
        "### Watch out for hallucinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y8kYxrSaHE9"
      },
      "source": [
        "Although LLMs have been trained on a large amount of data, they can generate text containing statements not grounded in truth or reality; these responses from the LLM are often referred to as \"hallucinations\" due to their limited memorization capabilities. Note that simply prompting the LLM to provide a citation isn't a fix to this problem, as there are instances of LLMs providing false or inaccurate citations. Dealing with hallucinations is a fundamental challenge of LLMs and an ongoing research area, so it is important to be cognizant that LLMs may seem to give you confident, correct-sounding statements that are in fact incorrect.\n",
        "\n",
        "Note that if you intend to use LLMs for the creative use cases, hallucinating could actually be quite useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NY5nAGeaJYS"
      },
      "source": [
        "Try the prompt like the one below repeatedly. We set the temperature to `1.0` so that it takes more risks in its choices. It's possible that it may provide an inaccurate, but confident answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QALPjEILaM62"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerateContentConfig(temperature=1.0)\n",
        "\n",
        "prompt = \"What day is it today?\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRkwzbgRbhKt"
      },
      "source": [
        "Since LLMs do not have access to real-time information without further integrations, you may have noticed it hallucinates what day it is today in some of the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c811e310d02"
      },
      "source": [
        "### Using system instructions to guardrail the model from irrelevant responses\n",
        "\n",
        "How can we attempt to reduce the chances of irrelevant responses and hallucinations?\n",
        "\n",
        "One way is to provide the LLM with [system instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction).\n",
        "\n",
        "Let's see how system instructions works and how you can use them to reduce hallucinations or irrelevant questions for a travel chatbot.\n",
        "\n",
        "Suppose we ask a simple question about one of Italy's most famous tourist spots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB6zJU76biFK"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerateContentConfig(temperature=1.0)\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=[\n",
        "            \"Hello! You are an AI chatbot for a travel web site.\",\n",
        "            \"Your mission is to provide helpful queries for travelers.\",\n",
        "            \"Remember that before you answer a question, you must check to see if it complies with your mission.\",\n",
        "            \"If not, you can say, Sorry I can't answer that question.\",\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "prompt = \"What is the best place for sightseeing in Milan, Italy?\"\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZa-Qcf9cF4A"
      },
      "source": [
        "Now let us pretend to be a user asks the chatbot a question that is unrelated to travel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZKBIDr2cGnu"
      },
      "outputs": [],
      "source": [
        "prompt = \"How do I make pizza dough at home?\"\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiUYIhwpctCy"
      },
      "source": [
        "You can see that this way, a guardrail in the prompt prevented the chatbot from veering off course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuuDhA37cvmP"
      },
      "source": [
        "### Turn generative tasks into classification tasks to reduce output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUCUrsUzczmb"
      },
      "source": [
        "#### Generative tasks lead to higher output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1xASHAkc46n"
      },
      "source": [
        "The prompt below results in an open-ended response, useful for brainstorming, but response is highly variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfXQWIacwRf"
      },
      "outputs": [],
      "source": [
        "prompt = \"I'm a high school student. Recommend me a programming activity to improve my skills.\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAmm9wPYc_1o"
      },
      "source": [
        "#### Classification tasks reduces output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRpK_0GdCpf"
      },
      "source": [
        "The prompt below results in a choice and may be useful if you want the output to be easier to control."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYDKh0r2dAqo"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"I'm a high school student. Which of these activities do you suggest and why:\n",
        "a) learn Python\n",
        "b) learn JavaScript\n",
        "c) learn Fortran\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTd60b1GdIsx"
      },
      "source": [
        "### Improve response quality by including examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJi44NejdJYE"
      },
      "source": [
        "Another way to improve response quality is to add examples in your prompt. The LLM learns in-context from the examples on how to respond. Typically, one to five examples (shots) are enough to improve the quality of responses. Including too many examples can cause the model to over-fit the data and reduce the quality of responses.\n",
        "\n",
        "Similar to classical model training, the quality and distribution of the examples is very important. Pick examples that are representative of the scenarios that you need the model to learn, and keep the distribution of the examples (e.g. number of examples per class in the case of classification) aligned with your actual distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMbLginWdOKs"
      },
      "source": [
        "#### Zero-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crh2Loi2dQ0v"
      },
      "source": [
        "Below is an example of zero-shot prompting, where you don't provide any examples to the LLM within the prompt itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7myRc-SdTQ4"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucRtPn9SdL64"
      },
      "source": [
        "#### One-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs0gQH2vdYBi"
      },
      "source": [
        "Below is an example of one-shot prompting, where you provide one example to the LLM within the prompt to give some guidance on what type of response you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEq-KxGYdaT5"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring üò†\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnKLjJzmdfL_"
      },
      "source": [
        "#### Few-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zv-9F5OdgI_"
      },
      "source": [
        "Below is an example of few-shot prompting, where you provide a few examples to the LLM within the prompt to give some guidance on what type of response you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u37P9tG4dk9S"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring üò†\n",
        "Sentiment: negative\n",
        "\n",
        "Tweet: Something surprised me about this video - it was actually original. It was not the same old recycled stuff that I always see. Watch it - you will not regret it.\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDMD3xb2dvX6"
      },
      "source": [
        "#### Choosing between zero-shot, one-shot, few-shot prompting methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s92W0YpNdxJp"
      },
      "source": [
        "Which prompt technique to use will solely depends on your goal. The zero-shot prompts are more open-ended and can give you creative answers, while one-shot and few-shot prompts teach the model how to behave so you can get more predictable answers that are consistent with the examples provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_intro"
      },
      "source": [
        "## Updates for Gemini 3 Pro\n",
        "\n",
        "**Quality Changes:**\n",
        "Customers migrating from 2.5 Pro to 3 Pro can expect to see significant improvements in high-level reasoning, complex instruction following, use of tools / agentic use cases, and better long context capabilities (including image and document understanding).\n",
        "\n",
        "**Behavior Changes:**\n",
        "Gemini 3 Pro is designed for high efficiency and action. It defaults to concise, direct answers and attempts to solve user intent immediately. Because the model prioritizes being helpful, it may occasionally guess when information is missing or prioritize a satisfying answer over strict instructions. Users can steer the model to curb this behavior with prompting.\n",
        "\n",
        "**Prompt Optimization:**\n",
        "We've detailed strategies that can help you control the model's output, ensure factual accuracy, and strictly enforce constraints. For any other quality regressions, please try prompting Gemini 3 Pro with the regression you're seeing like so:\n",
        "\n",
        "```md\n",
        "You are an expert prompt engineer. Rewrite the **Original Prompt** below to prevent the specific failure described in the **Bad Response** and **Feedback**. The new prompt should address the constraints and logic gaps that caused the error.\n",
        "\n",
        "**Original Prompt:**\n",
        "[Insert Prompt]\n",
        "\n",
        "**Bad Response:**\n",
        "[Insert Bad Response]\n",
        "\n",
        "**Feedback:**\n",
        "[Insert Feedback]\n",
        "\n",
        "**Output:** Provide only the optimized prompt with the changes that were made.\n",
        "```\n",
        "\n",
        "**Known Regressions:**\n",
        "3 Pro models do not prioritize supporting audio understanding or image segmentation use cases (use 2.5 Flash or Pro). For information dense or complicated graphs, tables, charts, etc, the model can incorrectly extract information or misinterpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_model_setup"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-3.1-pro-preview\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_temperature"
      },
      "source": [
        "### Temperature\n",
        "\n",
        "For Gemini 3, we strongly recommend keeping the temperature parameter at its default value of `1.0`.\n",
        "\n",
        "While previous models often benefited from tuning temperature to control creativity versus determinism, Gemini 3's reasoning capabilities are optimized for the default setting. Changing the temperature (setting it below `1.0`) may lead to unexpected behavior, such as looping or degraded performance, particularly in complex mathematical or reasoning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_deduction"
      },
      "source": [
        "### I. Distinguish between deduction and external information\n",
        "\n",
        "When you instruct the model with \"do not infer\" or \"do not guess,\" it may interpret this too strictly and refuse to perform basic logic (like arithmetic) or synthesize information found in different parts of a document.\n",
        "\n",
        "Instead of a blanket negative constraint, explicitly tell the model to use the provided text for deductions while banning outside knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_deduction_code"
      },
      "outputs": [],
      "source": [
        "less_effective_prompt = \"\"\"What was the profit? Do not infer.\"\"\"\n",
        "prompt = \"\"\"You are expected to perform calculations and logical deductions based strictly on the provided text. Do not introduce external information.\n",
        "\n",
        "Text: The company earned 50M revenue and had 30M costs.\n",
        "Question: What was the profit?\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_split_step"
      },
      "source": [
        "### II. Use split-step verification for unknown topics\n",
        "\n",
        "When the model encounters a topic it does not know (such as an obscure person) or a capability it does not have (such as accessing a specific live URL), it may generate plausible but incorrect information to satisfy the request.\n",
        "\n",
        "To prevent this, split the prompt into two steps: first verify the information or capability exists, then generate the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_split_step_code"
      },
      "outputs": [],
      "source": [
        "# Example prompt structure for checking capabilities before executing\n",
        "prompt = \"\"\"Verify with high confidence if you're able to access the NYT page. If you cannot verify, state 'No Info' and STOP. If verified, proceed to generate a response.\n",
        "\n",
        "Query: Summarize the headlines from NYT today\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_constraints_end"
      },
      "source": [
        "### III. Place most important constraints at the end of the prompt\n",
        "\n",
        "When dealing with complex requests, it may drop negative constraints (what *not* to do) or formatting or quantitative constraints (word counts) if they appear early in the prompt.\n",
        "\n",
        "Place your core ask and most critical restrictions, especially negative ones, as the final line of your instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_constraints_code"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"[Context and Source Material]\n",
        "Here is a list of fruits: Apple, Banana, Orange, Mango, Grape.\n",
        "\n",
        "[Main Task Instructions]\n",
        "Write a poem about these fruits.\n",
        "\n",
        "[Negative, Formatting, Quantitative Constraints]\n",
        "Do not use the letter 'e' in your poem. Keep it under 20 words.\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_persona"
      },
      "source": [
        "### IV. Use persona carefully\n",
        "\n",
        "The model treats the persona it is assigned seriously and will, sometimes, ignore instructions in order to maintain adherence to the described persona.\n",
        "\n",
        "Review the persona that's assigned to the model and avoid ambiguous situations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_persona_code"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are a data extractor. You are forbidden from clarifying, explaining, or expanding terms. Output text exactly as it appears. Do not explain why.\n",
        "\n",
        "Input: The user ID is 12345 (active status).\n",
        "Extract: User ID\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_grounding"
      },
      "source": [
        "### V. Help maintain grounding\n",
        "\n",
        "The model has strong internal knowledge and a desire to be helpful. If you provide a hypothetical scenario that contradicts real-world facts (e.g., \"The car was invented in 2024\"), the model may revert to its training data (1886) rather than your prompt or go off-book to be as helpful as possible.\n",
        "\n",
        "Explicitly state that the provided context is the only source of truth for the current session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_grounding_code"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Context: In this hypothetical world, the car was invented in the year 2024 by a time traveler.\n",
        "Question: When was the car invented? Disregard all outside knowledge. Use only the provided context, even if it contradicts facts you know.\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_synthesis"
      },
      "source": [
        "### VI. Synthesize information across the entire document / data\n",
        "\n",
        "If a document separates related information (e.g., a definition on Page 1 and a rule on Page 50), the model may stop reading after the first relevant match to avoid \"guessing.\"\n",
        "\n",
        "When working with large datasets (e.g., entire books, codebases, or long videos), place your specific instructions or questions at the end of the prompt, after the data context. Anchor the model's reasoning to the provided data by starting your question with a phrase like, \"Based on the entire document above...\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_synthesis_code"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"[Document Context Start]\n",
        "Part 1: The 'Flirble' is a small, blue creature.\n",
        "...\n",
        "[Long gap in text]\n",
        "...\n",
        "Part 10: Flirbles are known to fly only at night.\n",
        "[Document Context End]\n",
        "\n",
        "Based on the entire document above, provide a comprehensive answer. Synthesize all relevant information from the text that pertains to the question's scenario.\n",
        "Question: Describe the characteristics of a Flirble.\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini3_verbosity"
      },
      "source": [
        "### VII. Steering output verbosity\n",
        "\n",
        "By default, Gemini 3.0 is less verbose and prefers providing direct, efficient answers.\n",
        "\n",
        "If your use case requires a more conversational or \"chatty\" persona, you must explicitly steer the model in the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gemini3_verbosity_code"
      },
      "outputs": [],
      "source": [
        "prompt = \"Explain quantum entanglement as a friendly, talkative assistant.\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_prompt_design.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}